{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff31a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "import itertools  \n",
    "import collections\n",
    "import seaborn as sns\n",
    "# pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object of stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "df_tweet = pd.read_csv('Collected_tweet.csv')\n",
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cdcfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted column\n",
    "df_tweet.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf54f9",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "df_tweet['tweets_nostop'] = df_tweet['tweets'].apply(lambda x: clean_text(x.lower()))\n",
    "\n",
    "df_tweet.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce04ec8",
   "metadata": {},
   "source": [
    "# Stemming the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a83453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "df_tweet['tweets_stemmed'] = df_tweet['tweets_nostop'].apply(lambda x: stemming(x))\n",
    "\n",
    "df_tweet.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweet = pd.DataFrame({'text':df_tweet['tweets_lemmatized'], 'index':df_tweet.index})\n",
    "# df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object of dictionary\n",
    "dictionary = gensim.corpora.Dictionary(df_tweet['tweets_stemmed'] )\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 250:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the words\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in df_tweet['tweets_stemmed']]\n",
    "bow_corpus[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_doc_500 = bow_corpus[500]\n",
    "for i in range(len(bow_doc_500)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_500[i][0], \n",
    "                                               dictionary[bow_doc_500[i][0]], \n",
    "bow_doc_500[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d4940d",
   "metadata": {},
   "source": [
    "# LDA with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59094edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=100, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950b929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f1003",
   "metadata": {},
   "source": [
    "# Evalaute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet['tweets_stemmed'][300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee462f77",
   "metadata": {},
   "source": [
    "# LDA with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb9e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=25, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86abeb",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb313c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[300]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7150243",
   "metadata": {},
   "source": [
    "# Building the word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00233cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lda_model.num_topics):\n",
    "    wordcloud = WordCloud(width=400, stopwords=stopwords, height=200, max_font_size=20, max_words=200, collocations=False, \n",
    "                                background_color='black').generate(str(lda_model.show_topic(i,250)))\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26a3f4",
   "metadata": {},
   "source": [
    "# Masking the word cloud with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0cd0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "mask = np.array(Image.open('tesla.jpg'))\n",
    "wordcloud = WordCloud(width=1600, mask =   mask,stopwords=stopwords,height=800,max_font_size=200,max_words=50,\n",
    "                      collocations=False).generate(str(lda_model.show_topic(i,250)))\n",
    "f = plt.figure(figsize=(50,50))\n",
    "f.add_subplot(1,2, 1)\n",
    "plt.imshow(mask, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "plt.title('Original Image', size=40)\n",
    "plt.axis(\"off\")\n",
    "f.add_subplot(1,2, 2)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Generated Word Cloud', size=40)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853522e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud = []\n",
    "for i in range(lda_model.num_topics):\n",
    "    word_cloud.extend(list(dict(lda_model.show_topic(i)).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_df=pd.DataFrame({'Words':word_cloud})\n",
    "word_cloud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_df.to_csv('WC_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case = [word.lower() for word in word_cloud_df['Words']]\n",
    "lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360abab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have only unique words|\n",
    "set(lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba28e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_tweet = [tweet.lower().split() for tweet in lower_case]\n",
    "words_in_tweet[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6abfc",
   "metadata": {},
   "source": [
    "# A Bar Diagram showing the top-5 topics for any Twitter handler of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808cd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all words across tweets\n",
    "all_words = list(itertools.chain(*words_in_tweet))\n",
    "\n",
    "# Create counter\n",
    "counts = collections.Counter(all_words)\n",
    "\n",
    "counts.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical view\n",
    "clean_tweets = pd.DataFrame(counts.most_common(5),\n",
    "                             columns=['words', 'count'])\n",
    "\n",
    "clean_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f648e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical view\n",
    "sns.set(rc={'figure.figsize':(12,8),\"axes.titlesize\":20,\"axes.labelsize\":20})\n",
    "plot = sns.barplot(x=\"count\", y=\"words\", data=clean_tweets, palette=\"bright\")\n",
    "plot.set(xlabel='Count', ylabel='Words')\n",
    "plot.set_title('Top 5 Topics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7963e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
